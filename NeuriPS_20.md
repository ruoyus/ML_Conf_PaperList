FedSplit: an algorithmic framework for fast federated optimization
Reese Pathak (University of California, Berkeley) · Martin Wainwright (UC Berkeley)
12:18

Network Pruning via Greedy Optimization: Fast Rate and Efficient Algorithms
Mao Ye (The University of Texas at Austin) · Lemeng Wu (UT Austin) · Qiang Liu (UT Austin)
12:20
https://neurips.cc/Conferences/2020/AcceptedPapersInitial searched “optimization” in Neurips 20 paper list; only find 2 interesting papers.

neurips.cc
Accepted Papers
NeurIPS Website


The Generalization-Stability Tradeoff In Neural Network Pruning
Brian Bartoldson (Lawrence Livermore National Laboratory) · Ari Morcos (Facebook AI Research) · Adrian Barbu (Florida State University, USA) · Gordon Erlebacher (Florida State University)

12:25
Logarithmic Pruning is All You Need
Laurent Orseau (DeepMind) · Marcus Hutter (DeepMind) · Omar Rivasplata (DeepMind & UCL)

12:25
Batch Normalization Biases Residual Blocks Towards the Identity Function in Deep Networks
Soham De (DeepMind) · Sam Smith (Google Brain)
12:26

Escaping the Gravitational Pull of Softmax
Jincheng Mei (University of Alberta / Google Brain) · Chenjun Xiao (University of Alberta) · Bo Dai (Google Brain) · Lihong Li (Google Research) · Csaba Szepesvari (DeepMind / University of Alberta) · Dale Schuurmans (Google Brain & University of Alberta)
12:26

Training Generative Adversarial Networks by Solving Ordinary Differential Equations
Chongli Qin (DeepMind) · Yan Wu (DeepMind) · Jost Tobias Springenberg (DeepMind) · Andy Brock (DeepMind) · Jeff Donahue (DeepMind) · Timothy Lillicrap (DeepMind & UCL) · Pushmeet Kohli (DeepMind)
12:27

Your GAN is Secretly an Energy-based Model and You Should Use Discriminator Driven Latent Sampling
Tong Che (MILA) · Ruixiang ZHANG (Mila/UdeM) · Jascha Sohl-Dickstein (Google Brain) · Hugo Larochelle (Google Brain) · Liam Paull (Université de Montréal) · Yuan Cao (Google Brain) · Yoshua Bengio (Mila / U. Montreal)
12:28

Why Do Deep Residual Networks Generalize Better than Deep Feedforward Networks? --- A Neural Tangent Kernel Perspective
Kaixuan Huang (Princeton University) · Yuqing Wang (Georgia Institute of Technology) · Molei Tao (Georgia Institute of Technology) · Tuo Zhao (Gatech)
12:29

What Neural Networks Memorize and Why: Discovering the Long Tail via Influence Estimation
Vitaly Feldman (Google Brain) · Chiyuan Zhang (Google Brain)
12:29

What Do Neural Networks Learn When Trained With Random Labels?
Hartmut Maennel (Google) · Ibrahim Alabdulmohsin (Google Research) · Ilya Tolstikhin (Google, Brain Team, Zurich) · Robert Baldock (Google) · Olivier Bousquet (Google Brain (Zurich)) · Sylvain Gelly (Google Brain (Zurich)) · Daniel Keysers (Google Research, Brain Team)
12:30

The Surprising Simplicity of the Early-Time Learning Dynamics of Neural Networks
Wei Hu (Princeton University) · Lechao Xiao (Google Brain) · Ben Adlam (Google) · Jeffrey Pennington (Google Brain)
12:30

Top-k Training of GANs: Improving GAN Performance by Throwing Away Bad Samples
Samarth Sinha (University of Toronto, Vector Institute) · Zhengli Zhao (UCI, Google Brain) · Anirudh Goyal ALIAS PARTH GOYAL (Université de Montréal) · Colin A Raffel (Google Brain) · Augustus Odena (Google Brain)
12:31

The Unreasonable Effectiveness of Big Models for Semi-Supervised Learning
Ting Chen (Google) · Simon Kornblith (Google Brain) · Kevin Swersky (Google) · Mohammad Norouzi (Google Brain) · Geoffrey E Hinton (Google & University of Toronto)
12:31

Reparameterizing Mirror Descent as Gradient Descent
Ehsan Amid (University of California, Santa Cruz) · Manfred K. Warmuth (Google Brain)
12:32

Sanity-Checking Pruning Methods: Random Tickets can Win the Jackpot
Jingtong Su (Peking University) · Yihang Chen (Peking University) · Tianle Cai (Peking University) · Tianhao Wu (Peking University) · Ruiqi Gao (Peking University) · Liwei Wang (Peking University) · Jason Lee (Princeton University


12:33
Directional Pruning of Deep Neural Networks
Shih-Kang Chao (University of Missouri) · Zhanyu Wang (Purdue University) · Yue Xing (Purdue University) · Guang Cheng (Purdue University)
12:33

Pruning neural networks without any data by conserving synaptic flow
Hidenori Tanaka (NTT Research, PHI Lab / Stanford University) · Daniel Kunin (Stanford University) · Daniel Yamins (Stanford University) · Surya Ganguli (Stanford)
12:34

Optimal Lottery Tickets via Subset Sum: Logarithmic Over-Parameterization is Sufficient
Ankit Pensia (University of Wisconsin-Madison) · Shashank Rajput (University of Wisconsin - Madison) · Alliot Nagle (UW-Madison) · Harit Vishwakarma (University of Wisconsin Madison) · Dimitris Papailiopoulos (University of Wisconsin-Madison)
12:34

Winning the Lottery with Continuous Sparsification
Pedro Savarese (TTIC) · Hugo Silva (Independent Researcher) · Michael Maire (University of Chicago)
