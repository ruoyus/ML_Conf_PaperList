# Selection of accepted papers

## [Click HERE for the list of papers with scores.](https://docs.google.com/spreadsheets/d/1n58O0lgGI5kI0QQY9f4BDDpNB4oFjb5D51yMr9fHAK4/edit#gid=1546418007)



Global Convergence of Three-layer Neural Networks in the Mean Field Regime https://openreview.net/forum?id=KvyxFqZS_D 7.5 [7.0, 7.0, 7.0, 9.0] Accept (Oral)

Orthogonalizing Convolutional Layers with the Cayley Transform https://openreview.net/forum?id=Pbj8H_jEHYv 7.25 [7.0, 7.0, 7.0, 8.0] Accept (Spotlight)

Minimum Width for Universal Approximation https://openreview.net/forum?id=O-XJwyoIF-k 7.25 [8.0, 7.0, 7.0, 7.0] Accept (Spotlight)

On the Origin of Implicit Regularization in Stochastic Gradient Descent https://openreview.net/forum?id=rq_Qr0c1Hyo 7.25 [7.0, 7.0, 7.0, 8.0] Accept (Poster)

Federated Learning Based on Dynamic Regularization https://openreview.net/forum?id=B7v4QMR6Z9w 7.25 [7.0, 8.0, 7.0, 7.0] Accept (Oral)

Growing Efficient Deep Networks by Structured Continuous Sparsification https://openreview.net/forum?id=wb3wxCObbRT 7.25 [7.0, 7.0, 7.0, 8.0] Accept (Oral)

Benefit of deep learning with non-convex noisy gradient descent: Provable excess risk bound and superiority to kernel methods https://openreview.net/forum?id=2m0g1wEafh 7.25 [7.0, 8.0, 6.0, 8.0] Accept (Spotlight)

Why Are Convolutional Nets More Sample-Efficient than Fully-Connected Nets? https://openreview.net/forum?id=uCY5MuAxcxU 7.25 [7.0, 7.0, 8.0, 7.0] Accept (Oral)

Is Attention Better Than Matrix Decomposition? https://openreview.net/forum?id=1FvkSpWosOl 7.25 [6.0, 8.0, 8.0, 7.0] Accept (Poster)

Sharpness-aware Minimization for Efficiently Improving Generalization https://openreview.net/forum?id=6Tm1mposlrM 7.25 [7.0, 8.0, 6.0, 8.0] Accept (Spotlight)

Rethinking Architecture Selection in Differentiable NAS https://openreview.net/forum?id=PKubaeJkw3 7.75 [7.0, 7.0, 10.0, 7.0] Accept (Oral)

continue...